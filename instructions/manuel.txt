API
A venir...

Base de donnée cassandra

Créer une machine virtuelle avec une image ubuntu 16.04

Installation de Cassandra:
	Pour pouvoir installer Cassandra, il faut installer java. Vous pouvez le faire avec les étapes suivantes:
		1- sudo add-apt-repository ppa:webupd8team/java
		2- sudo apt-get update
		3- sudo apt-get install oracle-java8-set-default
		4- java -version (pas nécessaire, juste pour vérifier que vous avez installer java)

	Par des problèmes d'avertissement, il est nécessaire ajouter trois clés afin que cassandra marche parfaitement:
		Pour commencer, vous pouvez chercher les repos suivantes afin d'avoir accès aux clés
			1- echo "deb http://www.apache.org/dist/cassandra/debian 22x main" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list
			2- echo "deb-src http://www.apache.org/dist/cassandra/debian 22x main" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list
	
		Voici les commandes à executer pour installer les clés:
			1- gpg --keyserver pgp.mit.edu --recv-keys F758CE318D77295D
			2- gpg --export --armor F758CE318D77295D | sudo apt-key add -
			3- gpg --keyserver pgp.mit.edu --recv-keys 2B5C1B00
			4- gpg --export --armor 2B5C1B00 | sudo apt-key add -
			5- gpg --keyserver pgp.mit.edu --recv-keys 0353B12C
			6- gpg --export --armor 0353B12C | sudo apt-key add -

	Après d'avoir les clés, updater les packages:
		1- sudo apt-get update

	Enfin, installez Cassandra:
		1- sudo apt-get install cassandra



Spark

Installation et ajout de master à Spark
	1. Aller sur le site spark.org
	2. Télécharger spark-2.1.0-bin-hadoop2.4
	3. Après avoir installé Spark, aller dans le dossier "conf" du répertoire Spark
	4. Ouvrir un terminal et exécuter la commande "vi spark_env.sh"
	5. Ajouter les 4 lignes de codes suivant:
		SPARK_MASTER_HOST=127.0.0.1
		SPARK_LOCAL_IP=127.0.0.1
		SPARK_WORKER_INSTANCES=2
		SPARK_WORKER_CORES=1
	6. Sauvegarder le fichier et quitter
	7. Aller dans le dossier "sbin"
	8. Ensuite, exécuter la commande "./start-master.sh"
		Nous pouvons alors trouver notre master sur le port 8080, donc on peut tout simplement y avoir accès en entrant "localhost:8080"

Ajout des workers
	1. Copier le URL du master
	2. Exécuter la ligne suivante "./start-slave.sh " et ensuite coller le URL master que vous avez copié (par exemple: ./start-slave.sh spark://127.0.0.1:7077)
		Vous pouvez maintenant rafraîchir la page web du master et vous pouvez maintenant voir que les 2 workers sont présents

...
